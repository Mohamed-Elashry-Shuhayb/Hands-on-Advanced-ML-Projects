{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXSoAHZ4Kyzh"
      },
      "source": [
        "# Classifying movie reviews using CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkTEONME1nXP",
        "outputId": "2c4d84da-d652-4834-8bf5-d224a01eab90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import re\n",
        "import html\n",
        "import string\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRL1ymKKgwfs",
        "outputId": "4c62ee09-5f8e-4f21-f387-e69307746ca9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "DATA_PATH=Path('./dat/')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "#if not os.path.exists('./dat/aclImdb_v1.tar.gz'):\n",
        "if not os.path.exists('./dat/aclImdb'):\n",
        "    !curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "    !tar -xf aclImdb_v1.tar.gz -C {DATA_PATH}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  21.0M      0  0:00:03  0:00:03 --:--:-- 21.0M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6WR0hr1hkfP"
      },
      "source": [
        "Let's have a look on the raw data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBdi8Vrhg7oM"
      },
      "source": [
        "import numpy as np\n",
        "CLASSES = ['neg', 'pos']#, 'unsup']\n",
        "PATH=Path('./dat/aclImdb/')\n",
        "\n",
        "def get_texts(path):\n",
        "    texts,labels = [],[]\n",
        "    for idx,label in enumerate(CLASSES):\n",
        "        for fname in (path/label).glob('*.*'):\n",
        "            #texts.append(fixup(fname.open('r', encoding='utf-8').read()))\n",
        "            texts.append(fname.open('r', encoding='utf-8').read())\n",
        "            labels.append(idx)\n",
        "    #return np.array(texts),np.array(labels)\n",
        "    return texts, labels\n",
        "\n",
        "trn_texts,trn_labels = get_texts(PATH/'train')\n",
        "tst_texts,tst_labels = get_texts(PATH/'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA20l_K0hqkI",
        "outputId": "8ae8a96a-bd76-47e9-f09d-888b10d3ee67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for t in trn_texts[:10]:\n",
        "  print(t)\n",
        "  #print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This was one of the worst Wrestlemania's I've seen. It just didn't stand out at all, really. Card wise, I thought it was going to be pretty good, but every match just seemed to fall short.<br /><br />Chris Benoit vs. MVP One of the better matches. Benoit carried it. I just didn't think MVP was that great, but Benoit saved this match. <br /><br />Kane vs. Khali Wow, these two guys don't mix. Or maybe it's Khali and any other person alive don't mix. Awful match.<br /><br />Melina vs. Ashley I'm not a fan of female wrestling.<br /><br />ECW Originals vs. New Breed I was excited about this match, until I saw it. Really, Really disappointing.<br /><br />Edge vs. CM Punk vs. King Booker vs. Jeff Hardy vs. Matt Hardy vs. Mr. Kennedy vs. Finlay vs. Randy Orton Absolutely the worst MITB match so far. Just a major let down, to many people in the ring at the same time. It just didn't live up.<br /><br />Bobby Lashley vs. Umaga O.K. not extremely impressive, but not the worst of the night.<br /><br />Batista vs. Undertaker This was maybe the best match of the night. Very, very, very nice to see something good for a change. <br /><br />John Cena vs. Shawn Michaels I really feel like this match deserved to be last. People make a case for Batista vs. Undertaker, but this match was just as good. I am starting to get sick of seeing Cena win every match though. It's getting a little old. Now, I have to say, I feel this match is the best of the night, but I'm a huge Shawn Michaels fan, so I'm a little biased. Batista vs. 'Taker may have been better, but I'm biased, so...sorry. The last two were undoubtedly the best matches of the night and most everything else really came up short.\n",
            "The summary provided by my cable TV guide made it sound a lot more interesting than it actually is. \"Slaughterhouse Rock\" is by far the worst horror film that I have ever seen, a title previously held by \"Urban Legends: Final Cut\". From its opening scene I could tell it's going to be really bad, but I was so bored that I couldn't care less. This film contains laughable acting, especially by the guy who's tormented in his dreams, incredible as in not credible plot twists, and some of the crappiest music I've heard, and I'm living in a period when the likes of Britney Spears and Nsync dominate the air waves. The biggest problem with \"Slaughterhouse Rock\" is that it's not funny. One would a film as dull and boring and so NOT scary as this would try to spice things up a bit with a few funny one-liners here and there, but no. We have Tormented Guy's self-centered friend trying to be funny, but came across as annoying instead. (spoiler) And please, do tell me, who in this crazy world is insane and self-loathing enough to visit a creepy jail in the middle of the night? No one! If you're going to make a horror movie, at least make it believable. This one is anything but.\n",
            "Mr. VanHook took a good idea and kicked like a football. Unfortunately, it didn't make the goal. The historical subject of giants is a good one, but pour in the goon milk and you end up with a giant wheel of cheese. I say, take this reel wheel and roll it off a cliff. I couldn't even watch the entire film. That says a lot because I rarely walk away from any movie. I always like to give them a chance for last-minute redemption. It's impossible to redeem something this bad. Well, at least the acting was good....NOT! <br /><br />The only thing \"falling\" in this film is the rating. 1/10 and sinking into the negative numbers!\n",
            "This film deserves another bad review. Consider one reviewer extolling the film's virtues that include 'no sex, violence or gore.' Uh, excuse me. The very set-up of the film has us watching as Cody's young comrade, with love of life and who has everything to live for is blown to bits leaving Cody holding his lifeless, bloody body. And, given the nature of war we know that Cody has seen horror on almost a daily basis. So much for those viewing this film with such rose glasses that the violence which defines Cody's persona is erased from viewer memory.<br /><br />Sans any family of his own Cody, like John Rambo, roams the country on his bike making the long trek to hometown USA in the guise of some place called Nevada City. No mention, no realization of the clear fact that Cody is damaged goods. We know this since his CO practically declares him so as he order Cody to 'get some rest' away from the death and destruction of war. This explains, as none seem to notice or care, Cody's obvious 'flat' effect. It is not bad acting. It is the flat effect of post traumatic stress disorder. Not guessing here, remember his CO ordered him off the battle field.<br /><br />How about that 'accidental' kiss as noted by another review. The fall was an accident, the kiss was not. How exactly was Cody 'respecting' Faith by hitting on her knowing full well she was spoken for? Now that was a non-family value moment. A moment which is then announced to the immediate universe as if posted on YouTube. Of course faith's lapse of fidelity as well as Cody's 'coming on' to a woman who plans to marry another is received in the spirit of the Xmas season, all CHEERING their cheaten' hearts and lips.<br /><br />We know little about Faith's fianc√© except that she professes her love for him, she takes no longer than a nano second to accept his proposal (could have waited if any second thoughts), he is generous, he loves her to death, the family has nothing really against him, he believes marriage is based on compromises and the two have never discussed post marriage plans. No evil doers here.<br /><br />Asner is a fine actor given over the hill dialogue like 'we love you son....' 'You are part of our family' literally days after they have met a stranger named Cody. And the 'band of brothers' speech where the phrase was above all never intended to apply to virtual strangers off the battle field.<br /><br />Bottom line: This film is cotton candy Xmas fluff that betrays itself in major ways. Most grossly when it applauds Cody's disrespect for Faith by physically hitting on her knowing full well she is spoken for. By re-defining family as we know it to wit: accepting a virtual stranger as a full fledged loving member of the family because we all 'love you.' How many of you have done that or know anyone who has done that. NOT.\n",
            "This is one strange hacked together film, you get the feeling that the bond company had to come in on this one, I'm not surprised there's no credits on it, who would want to be associated with this film. The Acting of all involved is terribly stilted and the plot jumps around all over, it all makes very little sense. As I said before it looks like the bond company had to come in because it seems like there was alot of footage that wasn't shot that needed to be, and all the music was very ill-fitting library music (cheap I guess). Very, very odd. I might actually buy a DVD of it though, if it could let me in on what the hell was going on, and what happened to this movie.\n",
            "Maybe this isn't fair, because I only made it about halfway through the movie. One of the few movies I have actually not been able to watch due to lameness.<br /><br />The acting is terrible, the camera work is terrible, the plot is ridiculous and the whole movie is just unrealistic and cheesy. For example - during a coke deal, the coke is just kept loose in a briefcase - I'm no expert, but I think people generally put it in a bag.<br /><br />They use the same stupid sound effect whenever a punch is thrown (it's that over the top 'crunching' sound\" and they use toy guns with dubbed in sound effects.<br /><br />Worst movie ever.\n",
            "Inspector Gadget was probably my all-time favorite 80's cartoon. I enjoyed both the first and second seasons of the series as well as 1992's Christmas special \"Inspector Gadget Saves Christmas\". Some Gadget fans are quick to criticize the second season (1985) of the show, but they need to compare it to DiC's 2002 release of \"Inspector Gadget's Last Case: Claw's Revenge\" for then, they will find the second season to be absolute gold.<br /><br />Being a Gadget fan, I couldn't resist the opportunity to see the animated Inspector Gadget in something that wasn't Gadget Boy-related. I purchased the film, and I swore to myself that I'd be objective; I knew that sometimes artistic liberties would be taken from the original series. I was not even prepared for what I was about to watch.<br /><br />There was barely a shred of the original show still intact.<br /><br />Here is a short list of just some of the cons for this movie: *The humor is non-existent from the original series.<br /><br />*Penny and Brain (originally having a nearly equal part in the series as Gadget) are missing from the action for fifteen to twenty minute intervals.<br /><br />*The original music by Saban & Levy is not there, and the score that exists is sub-par. (Understood that Saban has his own production company now, but at least \"Inspector Gadget Saves Christmas\" had good music, even without Saban.) *Don't expect to see any of Gadget's gadgets which made the show so endearing, such as gadget-copter, gadget-brella, gadget-mallet,gadget-coat (which actually was used but it was not even called the same thing), as well as his standard other hat and hand gadgets. In this movie, his gadget legs were telescopic instead of springs. That kind of stuff annoys true fans of the show, and simply aren't necessary to change.<br /><br />*The gadgetmobile from the original series is now a fast-talking, supposedly \"hip\" convertible. All the fans from the original series enjoyed the gadgetmobile transforming into the gadget van and vice versa.<br /><br />*Chief Quimby is now very short-tempered and even mean to Gadget. He was always grumpy in the original series, but this pushes the situation a bit much.<br /><br />*Penny no longer has a computer book.<br /><br />Are there any positives to this movie? OK, here goes...<br /><br />*Maurice LaMarche does a good job of taking over for the great Don Adams as Inspector Gadget.<br /><br />*In one scene, Chief Quimby alludes to an actual villain from the cartoon series: the Great Wambini (classic \"Gadget\" villain from the second season, voiced by Louis Nye).<br /><br />Looking for more redeeming factors for this movie? Well, you're out of luck. Life is about making choices and living by those choices. Most situations in life have a purpose even if it is to teach a lesson. The lesson learned here: keep to the original formula! \"If it ain't broke, don't fix it.\" True Gadget fans should steer clear from this movie; you will surely be disappointed.<br /><br />Hopefully, DiC and Shout! Factory will continue to release more of the original series after the 2006 release of \"Inspector Gadget: The Original Series, Volume 1,\" containing the first 22 episodes of the series. As a true Gadget fan, lover of 80's animation and many of DiC's programs, I urge you the viewer to purchase \"Inspector Gadget: The Original Series, Volume 1\" and \"Inspector Gadget Saves Christmas\" DVD's which are excellent and sure to bring back good memories.\n",
            "I love all types of films, especially horror. That being said, Survival does not live up to ANY of the hype surrounding it.<br /><br />I can't give it any points on originality. There is nothing wrong with exploring the same themes, or remaking what others have done. It has just become a cop out for indie films to take us on a slasher journey through the woods, a crazed killer, and as of lately, throw in some crazy family. On those lines I have to compare it with the likes of Texas Chainsaw, Wrong Turn (though the twist in that one is obvious), and others. Survival falls up way short against comparable films. The plot was just not original in ANY way. Some films can get by with a weak (and way over-done) plot with superb acting, special fx, or a slew of other factors. Survivial doesn't have any of that to bank on. If you will, note the following: The acting in the movie never took off. I don't knock or blame the actors for that, nor the director. The dialogue was at best mediocre, and the actors involved never showed (not saying didn't HAVE) the talent to pull it off. I mention 2 standouts. The leading man in this film certainly has the look, but I seriously thinks he needs to consider more training before he is ready to carry a film. The actor who portrayed Greg also had potential, but we never got to see any of it (watch the movie to see why, you won't believe it..).<br /><br />The grainy film look. Ah yes, that little tid-bit of film making magic designed to take us to the glory days of \"Grindhouse\" films. In today's film making, that has become a gimmick. It either works or it doesn't. In this case it just does not work. There are too many other flaws going on, so it winds up distracting from the film, not adding to it. That being said, I think they did a good job of adding that grain. That is some good, quality grain. I think with a different script, better direction, and possibly actors, they should try another \"Grindhouse\" attempt. They will probably pull it off.<br /><br />As far as the tech aspects, in my opinion, they never quite gelled for me either. Better care could have been taken with audio (sounds like it was fed directly into the camera, but there is nothing wrong with that) and for being shot on DV, it was too soft for my taste.<br /><br />That is all I have to say about that.....\n",
            "After just finishing the book the same day I watched the movie, I knew what was supposed to happen. I had high expectations of the movie, because of the rating. The only reason I give this movie a 2 out of 10 stars is that it was alright trying to be a movie. I have a couple main points for not liking this movie.<br /><br />********** SPOILERS **********<br /><br />1. The casting. Jack Nicholson barely fits into Jack Torrence's character. Also, I would have NEVER picked Shelly Duvall for Wendy. I pictured Wendy much differently. I can see why they picked Jack Nicholson though, the grin, the pointy eyebrows, but he's not supposed to really look 'evil'. He's supposed to look normal, and he turns evil. Also, they make one of the worst movie couples. Danny was alright, he needed more life though. He acted way to droney.<br /><br />2. The screenplay. They cut out so many things that were in the book, and added things. Some of the things that were in the book that I was looking forward to in the movie were either deleted, changed, or handled wrongly. Some of the things that were in the book that I was looking forward to seeing (the hedge animals, the roque mallet, the elevator) were not in the movie, and it was 2 and half hours!! I was extremely irritated.<br /><br />3. The Ending. The ending was changed completly, Halorann died, Jack froze to death, Wendy never got hurt...The Overlook didn't blow up. The Ending was so cool in the book, and the movie messed it up so horribly, I was apalled. Hallorann was never supposed to die, but Jack killed him with an ax. If they wanted to kill him, at least have Jack use a roque mallet. You never even saw a roque mallet during the whole movie.<br /><br />There are other things that I didn't like about the movie, but there are things that were all right. The camera angels were cool, the blood coming out of the elevator (didn't happen in the book) was cool, but maybe I was too irritated that the movie didn't go with the book, to try to be scared at all. I reccomend reading the book, before you see this movie. I applaud Stephen King for actually agreeing to sign a contract to not dis Stanley Kubrik any more. I would never have done that, I would have taken all the rights I could get to yell at him all day. I can't wait to see the 6 hour version, at least it has the hedge animals.<br /><br />Rating: 2/10\n",
            "there is no suspense in this serial! When one episode ends the acting is so shoddy, the effects are so poor and the script is so awful that the last thing on your mind is how Batman and Robin will save the day. No, in fact, the last thing on your mind is watching the next episode! This show is so boring that I can't see how it ever got made, let alone released on DVD! Obviously the effects are not up to par with contemporary Batman films, but even the script is awful. An incoherent babbling mess about some evil professor and a ray gun or something like that, I am not quite sure, because it is too awful to follow. Watch the 60s version, or the 90's versions, or even Batman Begins, just anything over this version!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyZey5Pb1NiC"
      },
      "source": [
        "Let's start with the first phase:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdbVFwy3BDVE"
      },
      "source": [
        "# Text preprocessing\n",
        "\n",
        "In this phase, we apply some operations on the text, to make it in the most usable form for the task at hand. Mainly we clean it up to be more appealing to the problem we try to solve. The input is __text__ and the output is a transformed __text__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YzcLcAziSV2"
      },
      "source": [
        "def remove_special_chars(text):\n",
        "    re1 = re.compile(r'  +')\n",
        "    x1 = text.lower().replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
        "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
        "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n",
        "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
        "    return re1.sub(' ', html.unescape(x1))\n",
        "\n",
        "\n",
        "def remove_non_ascii(text):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "\n",
        "def to_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "\n",
        "def replace_numbers(text):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "\n",
        "def remove_whitespaces(text):\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "def remove_stopwords(words, stop_words):\n",
        "    \"\"\"\n",
        "    :param words:\n",
        "    :type words:\n",
        "    :param stop_words: from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "    or\n",
        "    from spacy.lang.en.stop_words import STOP_WORDS\n",
        "    :type stop_words:\n",
        "    :return:\n",
        "    :rtype:\n",
        "    \"\"\"\n",
        "    return [word for word in words if word not in stop_words]\n",
        "\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in text\"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    return [stemmer.stem(word) for word in words]\n",
        "\n",
        "def lemmatize_words(words):\n",
        "    \"\"\"Lemmatize words in text\"\"\"\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in text\"\"\"\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return ' '.join([lemmatizer.lemmatize(word, pos='v') for word in words])\n",
        "\n",
        "def text2words(text):\n",
        "  return word_tokenize(text)\n",
        "\n",
        "def normalize_text( text):\n",
        "    text = remove_special_chars(text)\n",
        "    text = remove_non_ascii(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = to_lowercase(text)\n",
        "    text = replace_numbers(text)\n",
        "    words = text2words(text)\n",
        "    stop_words = stopwords.words('english')\n",
        "    words = remove_stopwords(words, stop_words)\n",
        "    #words = stem_words(words)# Either stem or lemmatize\n",
        "    words = lemmatize_words(words)\n",
        "    words = lemmatize_verbs(words)\n",
        "\n",
        "    return ''.join(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYG1dzHtlp2J"
      },
      "source": [
        "Now let's apply this on the whole corpus:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpWFgR_Eltjt"
      },
      "source": [
        "def normalize_corpus(corpus):\n",
        "  return [normalize_text(t) for t in corpus]\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4MKyMgql2AT"
      },
      "source": [
        "trn_texts = normalize_corpus(trn_texts)\n",
        "tst_texts = normalize_corpus(tst_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIlsqxdFPPvi"
      },
      "source": [
        "# Data preparation for LSTM\n",
        "\n",
        "In this first part we use LSTM model.\n",
        "\n",
        "Few notes on RNNs:\n",
        "\n",
        "- RNNs are sequence models. This means we need to encode the sequence of words as sequence of words __indices__, which are obtained from the vocab.\n",
        "- __Keras tokenizer with Embedding layer__\n",
        "We will use Keras tokenizer. Index 0 is never given. If we use manual binarization and vocab building, we don't have this issue (which is actually NOT an issue, but intended as we will see below):\n",
        "\n",
        "This info is important when dealing later with Embedding layer in Keras, where padding with 0's might cause OOV if not considered, so we init that layer with vocab_size + 1 (to account for the missing 0). That layer also has option to mask_zero if needed for LSTM.\n",
        "\n",
        "Another solution would be to -1 from all binarized values. But this would make padded words same as UNK.\n",
        "\n",
        "In other words, it's a choice to have two different values for:\n",
        "\n",
        "A- UNK-->1\n",
        "B- PAD-->0\n",
        "\n",
        "In this case, the vocab_sz should increase by 1 (for pad), in case the model needs padding like LSTM.\n",
        "\n",
        "Or keep them both as 0. In this case, the vocab_sz remains the same as given from the tokenizer.\n",
        "\n",
        "- RNNs accept variable length inputs by definition. However, since Keras is a static framework (Except in Eager execution mode), it requires the data to have fixed length, hence we need to pad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzSUrqiSQ-aq"
      },
      "source": [
        "vocab_sz = 10000\n",
        "tok = Tokenizer(num_words=vocab_sz, oov_token='UNK')\n",
        "texts = trn_texts + tst_texts\n",
        "tok.fit_on_texts(texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs8A_h4tQ4kE"
      },
      "source": [
        "\n",
        "x_train = tok.texts_to_sequences(trn_texts)\n",
        "x_test = tok.texts_to_sequences(tst_texts)\n",
        "y_train = np.asarray(trn_labels).astype('float32')\n",
        "y_test = np.asarray(tst_labels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnpTWfi7QYjB"
      },
      "source": [
        "def get_max_len(texts):\n",
        "  return max([len(word_tokenize(text)) for text in texts])\n",
        "\n",
        "def pad_seq(seq, maxlen):\n",
        "  return np.array(pad_sequences(seq, maxlen=maxlen, padding='post', truncating='post'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxzOdkTWRZ1s"
      },
      "source": [
        "#maxlen = get_max_len(texts)\n",
        "maxlen = 100\n",
        "x_train = pad_seq(x_train, maxlen)\n",
        "x_test = pad_seq(x_test, maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvqSYVR96izl",
        "outputId": "61410135-7205-49ea-dc4b-899e9bcd6849",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 100)\n",
            "(25000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG9a44plSasO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.4, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTHC-UBdRvZ0",
        "outputId": "581f1b70-7081-4718-c5bc-d6d4d63e540e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
        "\n",
        "\n",
        "embedding_size = 100\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 64\n",
        "pool_size = 4\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocab_sz+1, embedding_size, mask_zero=True, input_length=maxlen)) No masking allowed for Conv1D\n",
        "model.add(Embedding(vocab_sz+1, embedding_size, input_length=maxlen))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "#model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_30 (Embedding)     (None, 100, 100)          1000100   \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 96, 64)            32064     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 24, 1)             65        \n",
            "=================================================================\n",
            "Total params: 1,032,229\n",
            "Trainable params: 1,032,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP5LLWCiSSAv",
        "outputId": "0f8dfa99-6e3b-40de-c90b-f1eb2f8afea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "gdrive_path = 'gdrive/My Drive/Colab Notebooks/DL NLP Course'\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, Callback\n",
        "model_name = 'basic'\n",
        "filepath = os.path.join(gdrive_path, 'imdb_lstm_' + model_name + '.h5')\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MIEsZwaSVE5",
        "outputId": "d68c37a0-68f7-4009-bbad-040b663befee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks_lst = [checkpoint]\n",
        "# Training\n",
        "batch_size = 256\n",
        "epochs = 20\n",
        "print('Train...')\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_val, y_val),\n",
        "          #validation_split=0.2,\n",
        "          callbacks=callbacks_lst)\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.6020WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 0.2339 - accuracy: 0.6020 - val_loss: 0.2156 - val_accuracy: 0.6426\n",
            "Epoch 2/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.2059 - accuracy: 0.6666WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.2059 - accuracy: 0.6661 - val_loss: 0.2106 - val_accuracy: 0.6523\n",
            "Epoch 3/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.6831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1979 - accuracy: 0.6831 - val_loss: 0.2101 - val_accuracy: 0.6540\n",
            "Epoch 4/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1931 - accuracy: 0.6919WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.1931 - accuracy: 0.6919 - val_loss: 0.2112 - val_accuracy: 0.6536\n",
            "Epoch 5/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.7007WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1891 - accuracy: 0.7006 - val_loss: 0.2124 - val_accuracy: 0.6517\n",
            "Epoch 6/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.1848 - accuracy: 0.7095WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.1850 - accuracy: 0.7087 - val_loss: 0.2141 - val_accuracy: 0.6503\n",
            "Epoch 7/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.7178WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1804 - accuracy: 0.7178 - val_loss: 0.2166 - val_accuracy: 0.6479\n",
            "Epoch 8/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.7266WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1761 - accuracy: 0.7267 - val_loss: 0.2190 - val_accuracy: 0.6461\n",
            "Epoch 9/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1721 - accuracy: 0.7350WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1720 - accuracy: 0.7349 - val_loss: 0.2211 - val_accuracy: 0.6445\n",
            "Epoch 10/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1678 - accuracy: 0.7437WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1680 - accuracy: 0.7432 - val_loss: 0.2238 - val_accuracy: 0.6420\n",
            "Epoch 11/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.1637 - accuracy: 0.7515WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1637 - accuracy: 0.7513 - val_loss: 0.2265 - val_accuracy: 0.6396\n",
            "Epoch 12/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1597 - accuracy: 0.7589WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.1597 - accuracy: 0.7589 - val_loss: 0.2288 - val_accuracy: 0.6391\n",
            "Epoch 13/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.7668WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1555 - accuracy: 0.7667 - val_loss: 0.2315 - val_accuracy: 0.6379\n",
            "Epoch 14/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.7747WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1512 - accuracy: 0.7745 - val_loss: 0.2341 - val_accuracy: 0.6358\n",
            "Epoch 15/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.1469 - accuracy: 0.7823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1471 - accuracy: 0.7819 - val_loss: 0.2365 - val_accuracy: 0.6351\n",
            "Epoch 16/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1426 - accuracy: 0.7899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1427 - accuracy: 0.7897 - val_loss: 0.2395 - val_accuracy: 0.6342\n",
            "Epoch 17/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1384 - accuracy: 0.7968WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1384 - accuracy: 0.7969 - val_loss: 0.2419 - val_accuracy: 0.6331\n",
            "Epoch 18/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.8045WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.1339 - accuracy: 0.8044 - val_loss: 0.2448 - val_accuracy: 0.6317\n",
            "Epoch 19/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.8112WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 25ms/step - loss: 0.1298 - accuracy: 0.8110 - val_loss: 0.2472 - val_accuracy: 0.6308\n",
            "Epoch 20/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.8182WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.1256 - accuracy: 0.8181 - val_loss: 0.2501 - val_accuracy: 0.6291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByZgYWFZNusO"
      },
      "source": [
        "As you can see, the output of the Conv1D and Maxpool1D is 3D tensor, including the temporal info (pooled over 4). We need to summarize this dimension.\n",
        "\n",
        "We have 2 options:\n",
        "\n",
        "1- LSTM: we will see later\n",
        "\n",
        "2- GlobalMaxPool1D: which takes the max over the temporal and feature dimensions https://stackoverflow.com/questions/43728235/what-is-the-difference-between-keras-maxpooling1d-and-globalmaxpooling1d-functi/43730861"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH1aqzqlOKI_",
        "outputId": "b89c0d1c-e0fe-4b5f-d307-4d1fc4ae085e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "\n",
        "\n",
        "embedding_size = 100\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 64\n",
        "pool_size = 4\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocab_sz+1, embedding_size, mask_zero=True, input_length=maxlen)) No masking allowed for Conv1D\n",
        "model.add(Embedding(vocab_sz+1, embedding_size, input_length=maxlen))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "#model.add(MaxPooling1D(pool_size=pool_size))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_31 (Embedding)     (None, 100, 100)          1000100   \n",
            "_________________________________________________________________\n",
            "conv1d_25 (Conv1D)           (None, 96, 64)            32064     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,032,229\n",
            "Trainable params: 1,032,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHhO9C0FOWh8",
        "outputId": "5832181e-88fb-40a1-ce50-332b14e75184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "from keras.callbacks import EarlyStopping\n",
        "callbacks_lst = [EarlyStopping(monitor='val_accuracy', mode='max')]\n",
        "# Training\n",
        "batch_size = 256\n",
        "epochs = 20\n",
        "print('Train...')\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_val, y_val),\n",
        "          #validation_split=0.2,\n",
        "          callbacks=callbacks_lst)\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/20\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.6666 - accuracy: 0.6563 - val_loss: 0.5934 - val_accuracy: 0.7651\n",
            "Epoch 2/20\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.4613 - accuracy: 0.8116 - val_loss: 0.4042 - val_accuracy: 0.8208\n",
            "Epoch 3/20\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.2993 - accuracy: 0.8807 - val_loss: 0.3808 - val_accuracy: 0.8316\n",
            "Epoch 4/20\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.2036 - accuracy: 0.9287 - val_loss: 0.3948 - val_accuracy: 0.8299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijrctlvn3GiA",
        "outputId": "d608fa09-fde0-45aa-fcbe-43bc1b3f05e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-obeJ3o3Hnd",
        "outputId": "c3f1e53e-8b97-40f4-a52e-9a1516cbd70c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZxk-HyoSIGN",
        "outputId": "4128919f-53de-4a80-bb73-c45c8a3742be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding, Activation\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "\n",
        "\n",
        "embedding_size = 128\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 64\n",
        "pool_size = 4\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(vocab_sz+1, embedding_size, mask_zero=True, input_length=maxlen)) No masking allowed for Conv1D\n",
        "#model.add(Embedding(vocab_sz+1, embedding_size, mask_zero=True, input_length=maxlen))\n",
        "model.add(Embedding(vocab_sz+1, embedding_size, input_length=maxlen))\n",
        "#model.add(Embedding(20000, embedding_size, input_length=100))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=pool_size))\n",
        "\n",
        "model.add(LSTM(70))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, 100, 128)          1280128   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_26 (Conv1D)           (None, 96, 64)            41024     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 24, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_22 (LSTM)               (None, 70)                37800     \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 1)                 71        \n",
            "=================================================================\n",
            "Total params: 1,359,023\n",
            "Trainable params: 1,359,023\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_TdDlvSSY7G",
        "outputId": "3c1a5908-dd7b-43ec-9f1e-117247d9c123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "from keras.callbacks import EarlyStopping\n",
        "callbacks_lst = [EarlyStopping(monitor='val_acc', mode='max')]\n",
        "# Training\n",
        "batch_size = 256\n",
        "epochs = 20\n",
        "print('Train...')\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_val, y_val),\n",
        "          #validation_split=0.2,\n",
        "          callbacks=callbacks_lst)\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.5870 - accuracy: 0.6679WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 39ms/step - loss: 0.5870 - accuracy: 0.6679 - val_loss: 0.3803 - val_accuracy: 0.8347\n",
            "Epoch 2/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.8894WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 31ms/step - loss: 0.2795 - accuracy: 0.8894 - val_loss: 0.3352 - val_accuracy: 0.8570\n",
            "Epoch 3/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.9413WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 31ms/step - loss: 0.1746 - accuracy: 0.9413 - val_loss: 0.3779 - val_accuracy: 0.8499\n",
            "Epoch 4/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.1163 - accuracy: 0.9644WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 31ms/step - loss: 0.1164 - accuracy: 0.9642 - val_loss: 0.4888 - val_accuracy: 0.8387\n",
            "Epoch 5/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9771WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0773 - accuracy: 0.9771 - val_loss: 0.5110 - val_accuracy: 0.8374\n",
            "Epoch 6/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9877WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 0.5994 - val_accuracy: 0.8331\n",
            "Epoch 7/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9881WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0450 - accuracy: 0.9881 - val_loss: 0.6102 - val_accuracy: 0.8307\n",
            "Epoch 8/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9923WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: 0.7228 - val_accuracy: 0.8308\n",
            "Epoch 9/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9943WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 30ms/step - loss: 0.0247 - accuracy: 0.9943 - val_loss: 0.7279 - val_accuracy: 0.8275\n",
            "Epoch 10/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9952WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.7418 - val_accuracy: 0.8282\n",
            "Epoch 11/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9963WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0169 - accuracy: 0.9963 - val_loss: 0.8230 - val_accuracy: 0.8303\n",
            "Epoch 12/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9972WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.8675 - val_accuracy: 0.8279\n",
            "Epoch 13/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9935WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 30ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.7510 - val_accuracy: 0.8281\n",
            "Epoch 14/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.0134 - accuracy: 0.9964WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.8096 - val_accuracy: 0.8317\n",
            "Epoch 15/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9971WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.8368 - val_accuracy: 0.8313\n",
            "Epoch 16/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 29ms/step - loss: 0.0081 - accuracy: 0.9982 - val_loss: 0.8993 - val_accuracy: 0.8272\n",
            "Epoch 17/20\n",
            "57/59 [===========================>..] - ETA: 0s - loss: 0.0085 - accuracy: 0.9974WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 30ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.8874 - val_accuracy: 0.8314\n",
            "Epoch 18/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9982WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 31ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.8920 - val_accuracy: 0.8336\n",
            "Epoch 19/20\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9988WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 30ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.8983 - val_accuracy: 0.8311\n",
            "Epoch 20/20\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9994WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "59/59 [==============================] - 2s 30ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 1.1306 - val_accuracy: 0.8247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OCu8_-PusRS"
      },
      "source": [
        "Notice how the performance drops with maxlen=1428. Keep in mind that the 1428 is mostly an outlier length. This results in a lot of padded zeros. Introducing a CNN1D over this sparse input produces a lot of useless features. So it's better to focus on smaller length, say 100. But to do this, it needs to be done when padding. It's useless to try to do it using input_length of Embedding, since it doesn't prevent longer sequence from passing."
      ]
    }
  ]
}